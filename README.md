Below is a list of publications that either propose AI documentation approaches or evaluate their use. 

You can access a sortable and filterable table [here](https://amywinecoff.github.io/ai-documentation/).

For each framework, we classified whether the approach primarily focused on data; models; systems; or methods, tasks, and processes. When a framework did not fit neatly into one of these categories, we assigned it to the most appropriate category or categories based on its primary focus. We also categorized the type of evaluation each framework or empirical research study employed. Frameworks
employing a "feasibility analysis" are those where the framework’s authors or another group applied the framework to create documentation for a hypothetical or actual dataset, model, system, or method. This type of analysis demonstrates that the framework could theoretically be used for its intended purpose but does not involve empirical evaluation with
practitioners in research or real-world settings. If a study developed a documentation artifact for the purpose of an empirical study, we classified this as part of the empirical study rather than as a feasibility analysis, as empirical studies offer a more rigorous evaluation. 
We classify publications as employing a "practitioner lab study" when the evaluation involved practitioners within a controlled research setting. We classify "practitioner real-world studies" as those examining practitioner methods and practices within their real-world work environments. Both lab and real-world studies have unique strengths, and
neither is inherently more rigorous or useful than the other. We define "artifact studies" as studies of publicly available documentation artifacts such as Github repository documentation or Hugging Face model cards. In some instances, framework authors mentioned consulting relevant stakeholders during the design or refinement of their framework. 
However, if these consultations were only briefly mentioned, we do not classify the work as including a practitioner study.

For our synthesis of findings from the majority of these frameworks and studies, see [Winecoff & Bogen, 2024](https://dl.acm.org/doi/abs/10.1145/3706598.3713814).  

| Author                                                                                                                                  |   Year | Title                                                                                                                                                                          | Framework Type           | Evaluation Type                               |
|:----------------------------------------------------------------------------------------------------------------------------------------|-------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|:----------------------------------------------|
| [Adkins et al.](https://dl.acm.org/doi/abs/10.1145/3491101.3519724)                                                                     |   2022 | Prescriptive and Descriptive Approaches to Machine-Learning Transparency                                                                                                       | Method, process, or task | Feasibility analysis                          |
| [Ahlawat, Winecoff, & Mayer](https://arxiv.org/abs/2409.06926)                                                                          |   2024 | Minimum Viable Ethics: From Institutionalizing Industry AI Governance to Product Impact                                                                                        | Evaluation only          | Practitioner real-world study                 |
| [Arnold et al.](https://ieeexplore.ieee.org/abstract/document/8843893)                                                                  |   2019 | FactSheets: Increasing trust in AI services through supplier's declarations of conformity                                                                                      | System                   | Feasibility analysis                          |
| [Baracaldo et al.](http://arxiv.org/abs/2202.12443)                                                                                     |   2022 | Towards an Accountable and Reproducible Federated Learning: A FactSheets Approach                                                                                              | System                   | Feasibility analysis                          |
| [Barker et al.](https://dl.acm.org/doi/abs/10.1145/3617694.3623239)                                                                     |   2023 | FeedbackLogs: Recording and Incorporating Stakeholder Feedback into Machine Learning Pipelines                                                                                 | Method, process, or task | Practitioner lab study                        |
| [Bender & Friedman](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00041/43452/Data-Statements-for-Natural-Language-Processing) |   2018 | Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science                                                                     | Data                     | Feasibility analysis                          |
| [Bhat et al.](https://dl.acm.org/doi/full/10.1145/3544548.3581518)                                                                      |   2023 | Aspirations and Practice of ML Model Documentation: Moving the Needle with Nudging and Traceability                                                                            | Evaluation only          | Practitioner lab study                        |
| [Blasch et al.](https://arxiv.org/abs/2102.03985)                                                                                       |   2020 | Multisource AI Scorecard Table for System Evaluation                                                                                                                           | System                   | Feasibility analysis                          |
| [Boyd](https://dl.acm.org/doi/10.1145/3479582)                                                                                          |   2021 | Datasheets for Datasets help ML Engineers Notice and Understand Ethical Issues in Training Data                                                                                | Evaluation only          | Practitioner lab study                        |
| [Brajovic et al.](http://arxiv.org/abs/2307.11525)                                                                                      |   2023 | Model Reporting for Certifiable AI: A Proposal from Merging EU Regulation into AI Development                                                                                  | System                   | Feasibility analysis                          |
| [Chang & Custis](https://dl.acm.org/doi/10.1145/3551624.3555301)                                                                        |   2022 | Understanding Implementation Challenges in Machine Learning Documentation                                                                                                      | Evaluation only          | Practitioner real-world study                 |
| [Chmielinski et al.](https://arxiv.org/abs/2201.03954)                                                                                  |   2020 | The Dataset Nutrition Label (2nd Gen): Leveraging Context to Mitigate Harms in Artificial Intelligence                                                                         | Data                     | Feasibility analysis                          |
| [Chmielinski et al.](https://perma.cc/YJT3-C6YM)                                                                                        |   2024 | The CLeAR Documentation Framework for AI Transparency Recommendations for Practitioners and Context for Policymakers                                                           | Method, process, or task | None                                          |
| [Crisan et al.](https://dl.acm.org/doi/abs/10.1145/3531146.3533108)                                                                     |   2022 | Interactive Model Cards: A Human-Centered Approach to Model Documentation                                                                                                      | Model                    | Practitioner lab study                        |
| [Díaz et al.](http://arxiv.org/abs/2402.05160)                                                                                          |   2024 | SoUnD Framework: Analyzing (So)Cial Representation in (Un)Structured (D)Ata                                                                                                    | Data                     | Feasibility analysis                          |
| [Gebru et al.](http://arxiv.org/abs/1803.09010)                                                                                         |   2021 | Datasheets for Datasets                                                                                                                                                        | Data                     | Feasibility analysis                          |
| [Geiger et al.](https://dl.acm.org/doi/abs/10.1145/3351095.3372862)                                                                     |   2020 | Garbage in, Garbage out? Do Machine Learning Application Papers in Social Computing Report Where Human-labeled Training Data Comes From?                                       | Evaluation only          | Artifact study                                |
| [Gilbert et al.](https://dl.acm.org/doi/abs/10.1145/3600211.3604698)                                                                    |   2023 | Reward Reports for Reinforcement Learning                                                                                                                                      | System                   | Feasibility analysis                          |
| [Heger et al.](https://dl.acm.org/doi/abs/10.1145/3555760)                                                                              |   2022 | Understanding Machine Learning Practitioners’ Data Documentation Perceptions, Needs, Challenges, and Desiderata                                                                | Evaluation only          | Practitioner real-world study                 |
| [Hind et al.](https://dl.acm.org/doi/abs/10.1145/3334480.3383051)                                                                       |   2019 | Experiences with Improving the Transparency of AI Models and Services                                                                                                          | Evaluation only          | Practitioner real-world study                 |
| [Holland et al.](https://arxiv.org/abs/1805.03677)                                                                                      |   2018 | The Dataset Nutrition Label: A Framework To Drive Higher Data Quality Standards                                                                                                | Data                     | Feasibility analysis                          |
| [Hupont & Gomez](https://ieeexplore.ieee.org/abstract/document/9953809)                                                                 |   2022 | Documenting Use Cases in the Affective Computing Domain Using Unified Modeling Language                                                                                        | Method, process, or task | Feasibility analysis                          |
| [Jorgensen](https://arxiv.org/abs/2508.14119)                                                                                           |   2025 | Documenting Deployment with Fabric: A Repository of Real-World AI Governance                                                                                                   | System                   | Practitioner lab study                        |
| [Laufer et al.,](https://arxiv.org/abs/2508.06811)                                                                                      |   2025 | Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face                                                                                                      | Evaluation only          | Artifact study                                |
| [Liang et al.](http://arxiv.org/abs/2402.05160)                                                                                         |   2024 | What’s Documented in AI? Systematic Analysis of 32K AI Model Cards                                                                                                             | Evaluation only          | Artifact study                                |
| [Liao et al.](https://dl.acm.org/doi/abs/10.1145/3544548.3580652)                                                                       |   2023 | Designerly Understanding: Information Needs for Model Transparency to Support Design Ideation for AI-Powered User Experience                                                   | Evaluation only          | Practitioner lab study                        |
| [Lucaj et al.](https://arxiv.org/abs/2508.08804)                                                                                        |   2025 | TechOps: Technical Documentation Templates for the AI Act                                                                                                                      | System                   | Practitioner lab study                        |
| [Marone & Van Durme](https://arxiv.org/abs/2508.08804)                                                                                  |   2023 | Data Portraits: Recording Foundation Model Training Data                                                                                                                       | Data                     | Feasibility analysis                          |
| [McMillan-Major et al.](https://aclanthology.org/2021.gem-1.11/)                                                                        |   2021 | Reusable Templates and Guides For Documenting Datasets and Models for Natural Language Processing and Generation: A Case Study of the HuggingFace and GEM Data and Model Cards | Data, Model              | Feasibility analysis                          |
| [McMillan-Major, Bender, & Friedman](https://dl.acm.org/doi/10.1145/3594737)                                                            |   2024 | Data Statements: From Technical Concept to Community Practice                                                                                                                  | Data                     | Practitioner lab study                        |
| [Miceli et al.](https://dl.acm.org/doi/10.1145/3442188.3445880)                                                                         |   2021 | Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices                                                                                                | Evaluation only          | Practitioner real-world study                 |
| [Mitchell et al.](https://dl.acm.org/doi/abs/10.1145/3287560.3287596)                                                                   |   2019 | Model Cards for Model Reporting                                                                                                                                                | Model                    | Feasibility analysis                          |
| [Mohammad](http://arxiv.org/abs/2107.01183)                                                                                             |   2022 | Ethics Sheets for AI Tasks                                                                                                                                                     | Method, process, or task | Feasibility analysis                          |
| [Moore, LIao, & Subramonyam](https://dl.acm.org/doi/abs/10.1145/3544548.3581242)                                                        |   2023 | fAIlureNotes: Supporting Designers in Understanding the Limits of AI Models for Computer Vision Tasks                                                                          | Evaluation only          | Practitioner lab study                        |
| [Nunes et al.](https://dl.acm.org/doi/10.1145/3554364.3559117)                                                                          |   2022 | Using Model Cards for Ethical Reflection: A Qualitative Exploration                                                                                                            | Evaluation only          | Practitioner lab study                        |
| [Papakyriakopoulos et al.](https://dl.acm.org/doi/abs/10.1145/3593013.3594049)                                                          |   2023 | Augmented Datasheets for Speech Datasets and Ethical Decision-Making                                                                                                           | Data                     | Feasibility analysis                          |
| [Pepe et al.](https://dl.acm.org/doi/abs/10.1145/3643916.3644412)                                                                       |   2024 | How do Hugging Face Models Document Datasets, Bias, and Licenses? An Empirical Study                                                                                           | Evaluation only          | Artifact study                                |
| [Procope et al.](https://perma.cc/BX4D-ZXP7)                                                                                            |   2022 | System-Level Transparency of Machine Learning                                                                                                                                  | System                   | Feasibility analysis                          |
| [Pushkarna et al.](https://dl.acm.org/doi/abs/10.1145/3531146.3533231)                                                                  |   2022 | Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI                                                                                                | Data                     | Practitioner real-world study                 |
| [Raji & Yang](http://arxiv.org/abs/1912.06166)                                                                                          |   2020 | ABOUT ML: Annotation and Benchmarking on Understanding and Transparency of Machine Learning Lifecycles                                                                         | System                   | None                                          |
| [Reid & Williams](http://arxiv.org/abs/2303.10721)                                                                                      |   2023 | Right the Docs: Characterising Voice Dataset Documentation Practices Used in Machine Learning                                                                                  | Evaluation only          | Practitioner real-world study, Artifact study |
| [Richards et al.](https://arxiv.org/abs/2006.13796)                                                                                     |   2020 | A Methodology for Creating AI FactSheets                                                                                                                                       | System                   | Feasibility analysis                          |
| [Roman et al.](http://arxiv.org/abs/2312.06153)                                                                                         |   2023 | Open Datasheets: Machine-Readable Documentation for Open Datasets and Responsible AI Assessments                                                                               | Data                     | Feasibility analysis                          |
| [Rostamzadeh et al.](https://dl.acm.org/doi/abs/10.1145/3531146.3533239)                                                                |   2022 | Healthsheet: Development of a Transparency Artifact for Health Datasets                                                                                                        | Data                     | Practitioner lab study                        |
| [Shen et al.](https://dl.acm.org/doi/10.1145/3531146.3533110)                                                                           |   2022 | The Model Card Authoring Toolkit: Toward Community-Centered, Deliberation-Driven AI Design                                                                                     | Model                    | Practitioner lab study                        |
| [Shimorina & Belz](http://arxiv.org/abs/2103.09710)                                                                                     |   2021 | The Human Evaluation Datasheet 1.0: A Template for Recording Details of Human Evaluation Experiments in NLP                                                                    | Method, process, or task | None                                          |
| [Soh](http://arxiv.org/abs/2111.02034)                                                                                                  |   2021 | Building Legal Datasets                                                                                                                                                        | Data                     | None                                          |
| [Sokol et al.](https://arxiv.org/abs/2410.12974)                                                                                        |   2025 | BenchmarkCards: Standardized Documentation for Large Language Model Benchmarks                                                                                                 | nan                      | Practitioner lab-study                        |
| [Sokol & Flach](https://dl.acm.org/doi/10.1145/3351095.3372870)                                                                         |   2020 | Explainability Fact Sheets: A Framework for Systematic Assessment of Explainable Approaches                                                                                    | Method, process, or task | Feasibility analysis                          |
| [Srinivasan et al.](https://openreview.net/forum?id=K7ke_GZ_6N)                                                                         |   2021 | Artsheets for Art Datasets                                                                                                                                                     | Data                     | Feasibility analysis                          |
| [Stoyanovich & Howe](https://perma.cc/3QVB-UZ9X)                                                                                        |   2019 | Nutritional Labels for Data and Models                                                                                                                                         | Data, Model              | Feasibility analysis                          |
| [Staufer et al.](https://arxiv.org/abs/2504.13839)                                                                                      |   2025 | Audit Cards: Contextualizing AI Evaluations                                                                                                                                    | Method, process, or task | Practitioner real-world study, Artifact study |
| [Subramaniam et al.](http://arxiv.org/abs/2103.07532)                                                                                   |   2023 | Comprehensive and Comprehensible Data Catalogs: The What, Who, Where, When, Why, and How of Metadata Management                                                                | Data                     | Practitioner lab study                        |
| [Sun et al.](https://dl.acm.org/doi/10.1145/3357384.3357853)                                                                            |   2019 | MithraLabel: Flexible Dataset Nutritional Labels for Responsible Data Science                                                                                                  | Data                     | Feasibility analysis                          |
| [Tagliabue et al.](http://arxiv.org/abs/2110.13601)                                                                                     |   2021 | DAG Card Is the New Model Card                                                                                                                                                 | Method, process, or task | Feasibility analysis                          |
| [Tang et al.](https://arxiv.org/abs/2503.23574)                                                                                         |   2025 | Navigating Uncertainties: Understanding How GenAI Developers Document Their Models on Open-Source Platforms                                                                    | Evaluation only          | Practitioner lab study, Artifact study        |
| [Yang et al.](https://dl.acm.org/doi/abs/10.1145/3183713.3193568)                                                                       |   2018 | A Nutritional Label for Rankings                                                                                                                                               | Method, process, or task | Feasibility analysis                          |
| [Zheng et al.](https://dl.acm.org/doi/abs/10.1145/3511808.3557115)                                                                     |   2022 | Network Report: A Structured Description for Network Datasets                                                                                                                  | Data                     | Practitioner lab study                        |
